{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119dc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from rich import print as prt\n",
    "from collections import Counter\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from jsonschema import validate, ValidationError, FormatChecker\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.utils.logger import log_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_schema(schema_path: str = \"../schemas/source_schema.json\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load the source schema from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        schema_path (str): Path to the JSON schema file\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: The loaded JSON schema\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the schema file doesn't exist\n",
    "        json.JSONDecodeError: If the JSON file is malformed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        schema_file = Path(schema_path)\n",
    "        if not schema_file.exists():\n",
    "            raise FileNotFoundError(f\"Schema file not found: {schema_path}\")\n",
    "        \n",
    "        with open(schema_file, 'r') as f:\n",
    "            schema = json.load(f)\n",
    "        \n",
    "        logger.info(f\"Successfully loaded source schema from {schema_path}\")\n",
    "        return schema\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"Schema file not found: {e}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Error parsing JSON schema: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df370f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_performance\n",
    "def validate_source_object(source_obj: Dict[str, Any], schema: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Validate a single source object against the source schema.\n",
    "    \n",
    "    Args:\n",
    "        source_obj (Dict[str, Any]): The source object to validate\n",
    "        schema (Dict[str, Any]): The JSON schema to validate against\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[bool, List[str]]: (is_valid, list_of_error_messages)\n",
    "    \"\"\"\n",
    "    validation_errors = []\n",
    "    \n",
    "    try:\n",
    "        # First, validate with jsonschema (handles most validation rules)\n",
    "        validate(instance=source_obj, schema=schema, format_checker=FormatChecker())\n",
    "        \n",
    "        # Additional custom validations:\n",
    "        # Validate ACM structure consistency\n",
    "        if \"acm\" in source_obj:\n",
    "            acm = source_obj[\"acm\"]\n",
    "            \n",
    "            if \"classif\" in acm and \"classif_type\" in acm:\n",
    "                # Check classification consistency\n",
    "                classif = acm[\"classif\"]\n",
    "                classif_type = acm[\"classif_type\"]\n",
    "                \n",
    "                if classif_type == \"US\" and classif not in \"U\":\n",
    "                    validation_errors.append(f\"Invalid classification '{classif}' for US type\")\n",
    "        \n",
    "        # Validate attributes structure\n",
    "        if \"attributes\" in source_obj:\n",
    "            attributes = source_obj[\"attributes\"]\n",
    "            \n",
    "            if \"data\" in attributes and isinstance(attributes[\"data\"], list):\n",
    "                for i, attr in enumerate(attributes[\"data\"]):\n",
    "                    if \"attributeName\" in attr and \"attributeValue\" in attr:\n",
    "                        # Check for empty or None values\n",
    "                        if not attr[\"attributeValue\"] or attr[\"attributeValue\"].strip() == \"\":\n",
    "                            validation_errors.append(f\"Empty attribute value for '{attr['attributeName']}' at index {i}\")\n",
    "        \n",
    "        # Validate location coordinates if present\n",
    "        if \"latestKnownLocation\" in source_obj:\n",
    "            location = source_obj[\"latestKnownLocation\"]\n",
    "            \n",
    "            if \"geometry\" in location and \"coordinates\" in location[\"geometry\"]:\n",
    "                coords = location[\"geometry\"][\"coordinates\"]\n",
    "                \n",
    "                if isinstance(coords, list) and len(coords) == 2:\n",
    "                    longitude, latitude = coords\n",
    "                    if not (-180 <= longitude <= 180):\n",
    "                        validation_errors.append(f\"Invalid longitude value: {longitude}\")\n",
    "                    \n",
    "                    if not (-90 <= latitude <= 90):\n",
    "                        validation_errors.append(f\"Invalid latitude value: {latitude}\")\n",
    "        \n",
    "        is_valid = len(validation_errors) == 0\n",
    "        return is_valid, validation_errors\n",
    "    \n",
    "    except ValidationError as e:\n",
    "        validation_errors.append(f\"Schema validation error: {e.message} at path: {e.absolute_path}\")\n",
    "        return False, validation_errors\n",
    "    except Exception as e:\n",
    "        validation_errors.append(f\"Unexpected validation error: {str(e)}\")\n",
    "        return False, validation_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63787adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_performance\n",
    "def validate_source_data(source_objects: List[Dict[str, Any]], schema_path: str = \"../schemas/source_schema.json\") -> Tuple[bool, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Validate all source objects against the source schema.\n",
    "    \n",
    "    This function validates each source object in the list against the provided schema,\n",
    "    logs any validation errors, and returns a comprehensive validation report.\n",
    "    \n",
    "    Args:\n",
    "        source_objects (List[Dict[str, Any]]): List of source objects to validate\n",
    "        schema_path (str): Path to the JSON schema file\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[bool, Dict[str, Any]]: (all_valid, validation_report)\n",
    "            - all_valid: True if all objects are valid, False otherwise\n",
    "            - validation_report: Dictionary containing detailed validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load the schema\n",
    "        schema = load_source_schema(schema_path)\n",
    "        \n",
    "        validation_report: Dict[str, Any] = {\n",
    "            \"total_objects\": len(source_objects),\n",
    "            \"valid_objects\": 0,\n",
    "            \"invalid_objects\": 0,\n",
    "            \"validation_errors\": {},\n",
    "            \"summary\": {\n",
    "                \"all_valid\": False,\n",
    "                \"error_types\": {},\n",
    "                \"most_common_errors\": []\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        all_errors = []\n",
    "        \n",
    "        for i, source_obj in enumerate(source_objects):\n",
    "            try:\n",
    "                is_valid, errors = validate_source_object(source_obj, schema)\n",
    "                \n",
    "                if is_valid:\n",
    "                    validation_report[\"valid_objects\"] += 1\n",
    "                    logger.debug(f\"Object {i} (ID: {source_obj.get('id', 'unknown')}) passed validation\")\n",
    "                else:\n",
    "                    validation_report[\"invalid_objects\"] += 1\n",
    "                    obj_id = source_obj.get('id', f'object_{i}')\n",
    "                    \n",
    "                    validation_report[\"validation_errors\"][obj_id] = errors\n",
    "                    all_errors.extend(errors)\n",
    "                    \n",
    "                    logger.warning(f\"Object {i} (ID: {obj_id}) failed validation with {len(errors)} errors:\")\n",
    "                    for error in errors:\n",
    "                        logger.warning(f\"  - {error}\")\n",
    "            except Exception as e:\n",
    "                validation_report[\"invalid_objects\"] += 1\n",
    "                obj_id = source_obj.get('id', f'object_{i}')\n",
    "                \n",
    "                error_msg = f\"Unexpected error during validation: {str(e)}\"\n",
    "                validation_report[\"validation_errors\"][obj_id] = [error_msg]\n",
    "                \n",
    "                all_errors.append(error_msg)\n",
    "                logger.error(f\"Object {i} (ID: {obj_id}) validation failed: {error_msg}\")\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        validation_report[\"summary\"][\"all_valid\"] = validation_report[\"invalid_objects\"] == 0\n",
    "        \n",
    "        # Count error types\n",
    "        error_type_counts = {}\n",
    "        for error in all_errors:\n",
    "            # Extract error type from error message\n",
    "            if \"schema validation\" in error.lower():\n",
    "                error_type = \"schema_validation\"\n",
    "            elif \"coordinate\" in error.lower() or \"longitude\" in error.lower() or \"latitude\" in error.lower():\n",
    "                error_type = \"coordinate_validation\"\n",
    "            elif \"empty\" in error.lower():\n",
    "                error_type = \"empty_values\"\n",
    "            else:\n",
    "                error_type = \"other\"\n",
    "            \n",
    "            error_type_counts[error_type] = error_type_counts.get(error_type, 0) + 1\n",
    "        \n",
    "        validation_report[\"summary\"][\"error_types\"] = error_type_counts\n",
    "        \n",
    "        # Get most common errors (top 5)\n",
    "        error_counter = Counter(all_errors)\n",
    "        validation_report[\"summary\"][\"most_common_errors\"] = error_counter.most_common(5)\n",
    "        \n",
    "        # Log summary\n",
    "        if validation_report[\"summary\"][\"all_valid\"]:\n",
    "            logger.info(f\"All {validation_report['total_objects']} source objects passed validation\")\n",
    "        else:\n",
    "            logger.warning(f\"Validation completed: {validation_report['valid_objects']}/{validation_report['total_objects']} objects valid\")\n",
    "            logger.warning(f\"Invalid objects: {validation_report['invalid_objects']}\")\n",
    "            logger.warning(f\"Error types found: {list(error_type_counts.keys())}\")\n",
    "        \n",
    "        return validation_report[\"summary\"][\"all_valid\"], validation_report\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to validate source data: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        \n",
    "        return False, {\n",
    "            \"total_objects\": len(source_objects) if source_objects else 0,\n",
    "            \"valid_objects\": 0,\n",
    "            \"invalid_objects\": len(source_objects) if source_objects else 0,\n",
    "            \"validation_errors\": {\"global_error\": [error_msg]},\n",
    "            \"summary\": {\n",
    "                \"all_valid\": False,\n",
    "                \"error_types\": {\"validation_failure\": 1},\n",
    "                \"most_common_errors\": [(error_msg, 1)]\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0381c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_objects(data_path):\n",
    "    \"\"\"\n",
    "    Get the source objects from the data folder and store them as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(data_path, \"r\") as f:\n",
    "            source_objects = json.load(f)\n",
    "        \n",
    "        if not isinstance(source_objects, list):\n",
    "            logger.error(\"Source objects should be a list of dictionaries.\")\n",
    "            return []\n",
    "        \n",
    "        logger.info(\"Source objects loaded successfully.\")\n",
    "        return source_objects\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"Source objects file not found.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(\"Error decoding JSON from source objects file.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the schema\n",
    "schema_path = \"../schemas/source_schema.json\"\n",
    "schema = load_source_schema(schema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/1_raw/source_objects.json\"\n",
    "source_objects = get_source_objects(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45115e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors = []\n",
    "\n",
    "try:\n",
    "    # First, validate with jsonschema (handles most validation rules)\n",
    "    validate(instance=source_objects[0], schema=schema, format_checker=FormatChecker())\n",
    "    print(\"Single object validation passed!\")\n",
    "except ValidationError as e:\n",
    "    print(\"Validation failed!\")\n",
    "    print(f\"Error: {e.message}\")\n",
    "    print(f\"Field: {e.absolute_path}\")\n",
    "    print(f\"Expected: {e.schema.get('type', 'unknown type')}\")\n",
    "    print(f\"Actual value: {e.instance} (type: {type(e.instance).__name__})\")\n",
    "    \n",
    "    # Show the problematic data\n",
    "    print(\"\\nProblematic field in your data:\")\n",
    "    print(f\"source_objects[0]['version'] = {source_objects[0]['version']} (type: {type(source_objects[0]['version']).__name__})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the source objects against the schema\n",
    "print(\"Validating source objects against schema...\")\n",
    "all_valid, validation_report = validate_source_data(source_objects)\n",
    "\n",
    "print(\"Validation Summary:\")\n",
    "print(f\"Total objects: {validation_report['total_objects']}\")\n",
    "print(f\"Valid objects: {validation_report['valid_objects']}\")\n",
    "print(f\"Invalid objects: {validation_report['invalid_objects']}\")\n",
    "print(f\"Overall result: {'PASSED' if all_valid else 'FAILED'}\")\n",
    "\n",
    "if not all_valid:\n",
    "    print(\"Error Analysis:\")\n",
    "    error_types = validation_report['summary']['error_types']\n",
    "    \n",
    "    for error_type, count in error_types.items():\n",
    "        print(f\"  - {error_type}: {count} errors\")\n",
    "    \n",
    "    if validation_report['summary']['most_common_errors']:\n",
    "        print(\"Most Common Errors:\")\n",
    "        for error, count in validation_report['summary']['most_common_errors'][:3]:\n",
    "            print(f\"  - ({count}x) {error}\")\n",
    "    \n",
    "    # Show details for first few invalid objects\n",
    "    invalid_objects = list(validation_report['validation_errors'].keys())[:3]\n",
    "    \n",
    "    if invalid_objects:\n",
    "        print(\"Sample Invalid Objects:\")\n",
    "        for obj_id in invalid_objects:\n",
    "            errors = validation_report['validation_errors'][obj_id]\n",
    "            print(f\"  Object ID: {obj_id}\")\n",
    "            \n",
    "            for error in errors[:2]:  # Show first 2 errors per object\n",
    "                print(f\"    - {error}\")\n",
    "            if len(errors) > 2:\n",
    "                print(f\"    ... and {len(errors) - 2} more errors\")\n",
    "            print()\n",
    "\n",
    "print(\"Validation report available in 'validation_report' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fe8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb3dda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e5ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
